{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-Parameter Tuning (Embedding model)\n",
    "This document tunes hyperparameters for use in the \"Category-embedding\" NLP+LSTM model that performs text classification of consumer complaints. The model is run in the companion script here [here](https://github.com/faraway1nspace/NLP_topic_embeddings/blob/master/FinComplain_LSTM_embedding_model.ipynb). This model is an elaboration of a more generic [LSTM-NLP model](https://github.com/faraway1nspace/NLP_topic_embeddings/blob/master/FinComplain_LSTM_default_model.ipynb); the category embedding is inspired by the famous [instacart model](https://tech.instacart.com/deep-learning-with-emojis-not-math-660ba1ad6cdc). The key hyperparameter is the embedding dimension of the category embeddings.\n",
    "\n",
    "<b>Hyperparameters</b> should be done by minimizing a cross-validation loss. In this script, I use a <b>Thompson-sampler</b> (inspired by a cruide _reinforcement-learning_ / multi-arm bandit algorithm), to stochastically explore the high-dimensional hyperparameter space and find good hyperparameter values. This is an original algorithm and is untested, but it seems to work well.\n",
    "\n",
    "The hyperparameters include:\n",
    "+ the embedding dimension of the category embedding\n",
    "+ the embedding dimension of the word-embedding (like word2vec) \n",
    "+ the size of the corpus used in the word-tokenization (which feeds into the word-embedding). \n",
    "+ the dimensionality of the Long-Short-Term-memory outputs\n",
    "+ the Dropout rate in the LSTM\n",
    "\n",
    "... as well as choosing total number of epochs to run the LSTM.\n",
    "\n",
    "### Category Embeddings\n",
    "The category embedding learns a low-dimensional representation of the >400 different financial complaint Issues in the US Financial Consumer Protection [complaint database](https://www.consumerfinance.gov/data-research/consumer-complaints/). The number of embedding dimensions should be much less than the number of categories, at most 1/2, and probably much less than the sqrt(#[categories]). More dimensions means a potentially better representation but higher variance and redundancy; fewer dimensions means more bias but lower variance: it is a classic trade-off, and should be treated as a hyperparameter. If the embeddings have no affect on predictive performance, then this should be reflected in uncertainty in the hyper-parameter tuning algorithm.\n",
    "\n",
    "During an Insight Data fellowship, I used this technique on a similar proprietary dataset for sentiment analysis, and found it help us make sense of the (growing) number of consumer-product categories.\n",
    "\n",
    "### Function overview\n",
    "+ `run_model` The main function which runs an individual cross-validation run \n",
    "+ `proposal_hyperparam` The main thompson sampler function which proposes new samples from the hyperparameter space.\n",
    "\n",
    "The procedure is straight forward\n",
    "+ get <b>samples</b> from the hyperparameter space\n",
    "+ do <b>3-fold cross-validation</b> to estimate an Expected Loss (aka hold-out loss)\n",
    "+ use the Expected Loss as the 'reward' in a <b>multi-arm bandit learner</b>\n",
    "+ calculate <b>probabilities</b> for each combination of hyperparameters\n",
    "+ use the <b>Thompson-sampler</b>/multi-arm bandit algorithm to draw a new sample from the hyperparameter space\n",
    "+ <b>repeat</b> for about 30 iterations.\n",
    "\n",
    "The multi-arm bandit learner should progressively sample from the hyperparameter space that has a higher-probability of minimizing the Expected Loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions: Data Import & Natural Language Pre-Processing\n",
    "\n",
    "The following functions are some idiosyncratic functions to import and clean the Financial complaint data. For the background of the data source and the models' purpose, please see the [Readme file](https://github.com/faraway1nspace/NLP_topic_embeddings) as well as the [US Consumer Complaint Database](https://www.consumerfinance.gov/data-research/consumer-complaints/) at the US Consumer Financial Protection Bureau website.\n",
    "+ `import_and_clean_data` : reads the complaint data and organizes it for the `keras` LSTM model\n",
    "+ `nlp_preprocess` \" does some basic NLP pre-processing (stemming, removing stop words, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib notebook\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from math import log,exp\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import download as nltk_downloader \n",
    "from keras import backend as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Embedding, LSTM, RepeatVector, concatenate, Dense, Reshape, Flatten\n",
    "from keras.models import Model\n",
    "from scipy.stats import rankdata as rd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# set the working directory\n",
    "#os.chdir(\"...\")\n",
    "\n",
    "# NLP function to replace english contractions\n",
    "def decontracted(phrase):\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "# function to do some basic NLP pre-processing steps: replacing contractions, stemming words, removing stop words\n",
    "def nlp_preprocess(text_column, # column in Panda table with text\n",
    "                   stop_words, # list of English stopwords\n",
    "                   word_clip = 300): # truncate the number of words\n",
    "   # remove contractions\n",
    "   ps = PorterStemmer()  # stemmer    \n",
    "   cTextl = [decontracted(x) for x in text_column.values.tolist()]\n",
    "   # remove double spacing and non-alphanumeric characters\n",
    "   cTextl=[re.sub(' +',' ',re.sub(r'\\W+', ' ', x)) for x in cTextl]\n",
    "   # lower case the words\n",
    "   cTextl = [x.lower() for x in cTextl]\n",
    "   # stop words and stemming\n",
    "   for i in range(0,len(cTextl)):\n",
    "      rawtext = cTextl[i].split(\" \") # splits sentence by spaces\n",
    "      rawtext = rawtext[0:min(word_clip,len(rawtext))] # take only 300 words maximum\n",
    "      # stem and remove stopwords in one line (expensive operation)\n",
    "      newtext = \" \".join(ps.stem(word) for word in rawtext if not word in stop_words)  # loop through words, stem,join\n",
    "      cTextl[i] = newtext\n",
    "   return pd.DataFrame(cTextl)\n",
    "\n",
    "# function: import and pre-process the data (prepare for Keras)\n",
    "def import_and_clean_data(filename, # file name of data to import (either a .csv or a tar.xz file of a .csv)\n",
    "                          col_label = \"Label3\",\n",
    "                          data_dir = \"data/\", # directory\n",
    "                          tmp_dir = \"/tmp/\", # if file is a .tar.xz, where to temporarily extract the data (Windows users need specify differently than /tmp/\n",
    "                          rare_categories_cutoff = 10, # threshold for categories to be included in the training set\n",
    "                          word_clip = 300): # max number of words in text to accept (only first 300 words are retained\n",
    "   # check\n",
    "   if \"tar.xz\" in filename:\n",
    "      print(\"decompressing \" + filename + \" into \"+tmp_dir)\n",
    "      # command for shell\n",
    "      os_system_command = \"tar xf \"+data_dir+filename+\" -C \"+tmp_dir\n",
    "      print(os_system_command)\n",
    "      # run decompression command (for Linux/Mac)\n",
    "      os.system(os_system_command)\n",
    "      newfilename = tmp_dir + filename.split(\".tar.xz\")[0]\n",
    "   else:\n",
    "      print(\"importing csv called \" + filename)\n",
    "      newfilename = data_dir + filename\n",
    "   # read the complaint data \n",
    "   d_raw = pd.read_csv(newfilename, usecols = ['State','Complaint ID','Consumer complaint narrative','Product', 'Sub-product', 'Issue', 'Sub-issue'])\n",
    "   print(\"imported \" + str(d_raw.shape[0]) + \" rows of data\") # notice 191829 rows and 7 columns\n",
    "   # fill NaN with blanks\n",
    "   for col_ in ['Product','Sub-product','Issue']:\n",
    "      d_raw[col_] = d_raw[col_].fillna(\" \") # fill NaN with a character\n",
    "   # factorize the two levels (Product and Product+Issue) to get unique values\n",
    "   d_raw['Label1'] = pd.factorize(d_raw['Product'])[0]\n",
    "   # combine Product + Issues\n",
    "   d_raw['Label3'] = pd.factorize(d_raw['Product'] + d_raw['Sub-product']+d_raw['Issue'])[0] # 570 Categories\n",
    "   # Dictionary: category integers vs. category names\n",
    "   cats = [pd.factorize(d_raw['Product'])[1],  pd.factorize(d_raw['Product'] + d_raw['Sub-product'])[1], pd.factorize(d_raw['Product'] + d_raw['Sub-product']+d_raw['Issue'])[1]]\n",
    "   # truncate the data: only use categories with at least 10 observations\n",
    "   labels_counts = d_raw.groupby([col_label]).size() # counts of Level3 categories \n",
    "   which_labels = np.where(labels_counts>=rare_categories_cutoff)[0] # which categories have at least 'cutoff'\n",
    "   # make new (truncated) dataset\n",
    "   ixSubset = d_raw.Label3.isin(which_labels) # subset integers\n",
    "   # new dataset 'd', as subset of d_raw\n",
    "   d = (d_raw[ixSubset]).copy()\n",
    "   # NLP pre-processing: stopwords removal, stemming, etc.\n",
    "   # get the default English stopwords from nlkt pacakge\n",
    "   from nltk.corpus import stopwords \n",
    "   stop_words = set(stopwords.words('english')) # list of stopwords to remove\n",
    "   # get the stemming object from nltk\n",
    "   ps = PorterStemmer()  # stemmer\n",
    "   # column in data with the Text data (to feed into the LSTM)\n",
    "   col_text = 'Consumer complaint narrative' # name of the column with the text \n",
    "   # NLP: pre-process the text/complaints\n",
    "   print(\"performing NLP pre-processing on column \" + col_text + \" (remove stop words, stemming,...). This may take a while...\")\n",
    "   cText = nlp_preprocess(d[col_text],stop_words, word_clip = word_clip)\n",
    "   print(\"Done NLP pre-processing\")\n",
    "   # process the labels, make into a N-hot-coding matrix \n",
    "   Y = pd.get_dummies(d['Label3'].values) # one-hot coding\n",
    "   # get integers representing each (label3) class (these are the column names)\n",
    "   Ynames_int = Y.columns # notice the confusing mapping of different integers to different integers\n",
    "   # get english issue labels corresponding to each integer value in Ynames_int\n",
    "   Ynames_char = [cats[2][i] for i in Ynames_int] # actual names\n",
    "   # Finally, convert Y into a numpy matrix (not a panda df)\n",
    "   Y = Y.values\n",
    "   n_obs = Y.shape[0]\n",
    "   # make the input data for the category embedding\n",
    "   uLabels3 = d['Label3'].unique() # unique level 3 labels\n",
    "   nLabels3 = len(uLabels3) # number of unique level 3 labels\n",
    "   X_labels  = np.repeat(np.array([i for i in range(0,nLabels3)],dtype=int).reshape(1,nLabels3),n_obs,axis=0) # input for embedding layer\n",
    "   print(\"returning cleaned text data 'cText' for use in tokenization; 'Y' as an one-hot-coding matrix of categories; and 'cats' a dictionary matches columns in Y to english category names\")\n",
    "   if \"tar.xz\" in filename:\n",
    "      print(\"deleting temporary file \" + filename)\n",
    "      os_system_command = \"rm \"+ newfilename\n",
    "      print(os_system_command)\n",
    "      os.system(os_system_command)\n",
    "      print(\"done pre-processing\")\n",
    "   return cText, Y, X_labels,cats\n",
    "\n",
    "# function to calculate sample_weights for keras argument sample_weight\n",
    "def get_class_weights(Y, # N-hot-coding response matrix\n",
    "                      clip_ = 100000): # maximum weight for rarer cases\n",
    "   weights_total_class_counts = (Y).sum(axis=0)\n",
    "   weights_by_class = (min(weights_total_class_counts)/weights_total_class_counts) # weight by the rarest case\n",
    "   Y_int = np.argmax(Y,axis=1)\n",
    "   vWeights_raw = np.array([weights_by_class[i] for i in Y_int], dtype=float)\n",
    "   vWeights = np.clip(vWeights_raw * (Y.shape[0]/sum(vWeights_raw)),0,clip_)\n",
    "   return vWeights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions: Hyperparameter Sampling\n",
    "\n",
    "With 4 hyperparameters and (at least) 3 discrete values each, I explored 81 possible _combinations_ of hyperparameter (for an academic or production-level project, you'd likely want more fine-grained hyperparameter values). The goal is to find the best combination of hyperparameter values, based on a cross-validation loss (Expected Loss). It is very inefficient to do cross-validation on EVERY combination. Instead, we'll do a <b>stochastic search</b> across the space of hyperparameter combinations, arriving at the best combination much earlier than running all 81 combinations.\n",
    "\n",
    "#### Thompson sampling:\n",
    "Stochastic exploration of the hyperparameter space requires some way to calculate _probabilities_ for each combination of hyperparameters. I use a simple principle from reinforcement learning called <b>Thompson sampling</b>: the more _uncertain_ a potential action/reward is, the more _likely_ we should try it, and thus reduce our uncertainty quickly find the most rewarding action. Here _action_ means picking a combination of hyperparameters to estimate the Expected Loss; and _reward_ is finding the lowest Expected Loss.\n",
    "\n",
    "#### Model uncertainty as a Dirichlet-Multinomial process\n",
    "The key innovation I present is my method to estimate the probabilities for each hyperparameter combination: this will involve an ensemble of penalized-regressors (`Ridge` and `DecisionTreeRegressor` from `sklearn`). The regressors will estimate the Expected Loss of each combination using the hyperparameter variables as predictor variables. The _frequency counts_ of each hyperparameter-combination being the best model (lowest predicted loss) is converted into a probability via the <b>Dirichlet-Multinomial</b> process. \n",
    "\n",
    "There are a bunch of functions, the main ones pertaining to the hyperparameters are:\n",
    " + `make_hyperparameters_combos` : takes a dictionary of hyperparameters values and makes a grid of all possible combinations\n",
    " + `optimal_order_of_hyperparameter_runs` : proposes an optimal sequence in which to run the different combination of hyperparameter values. This will find high-contrasting parameter-combinations, so that the space of hyperparameter values is quickly explored deterministically, prior to evoking the multi-arm bandit algorithm\n",
    " + `proposal_hyperparam`: main Thompson sampler; proposes new combinations of hyperparameters to run in cross-validation. It switches between a deterministic algorithm and a stochastic algorithm after a preset number of iterations (`toggle_learner`). There are other hyper-hyper-parameters that govern the learning behaviour of the multi-arm-bandit process (`ridge_alpha`, `max_depth`,`multinomial_prior`) and should be left as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal function for cross-validation: creates all combinations of hyperparameters\n",
    "def make_hyperparameters_combos(hyper_parameters):\n",
    "   # hyperparmeters' values\n",
    "   hyp_args = [x[1] for x in hyper_parameters.items()]\n",
    "   # names of hyperparameters\n",
    "   hyp_names = [x[0] for x in hyper_parameters.items()]\n",
    "   # all combos of hyperparameters, as a tensor\n",
    "   hyp_args_grid = np.meshgrid(*hyp_args)\n",
    "   # dimensions of the hyperparameters\n",
    "   hyp_args_dimensions = list(hyp_args_grid[0].shape)\n",
    "   # total number of hyperparameter combos\n",
    "   total_combos = round(exp(sum(map(log,hyp_args_dimensions))))\n",
    "   # reshape into a [n_combos,parameters]\n",
    "   hyp_grid = (np.array(hyp_args_grid).reshape(len(hyp_args_grid),total_combos)).T\n",
    "   # convert grid to data.frame\n",
    "   hyp_pd = pd.DataFrame(hyp_grid, columns = hyp_names)\n",
    "   # also make a companion sequence\n",
    "   hyp_seq = [[j for j in range(0,len(x[1]))] for x in hyper_parameters.items()]\n",
    "   hyp_seq_grid = (np.array(np.meshgrid(*hyp_seq)).reshape(len(hyp_args_grid),total_combos)).T\n",
    "   # make an empty panda data.frame to fill with results\n",
    "   empty_res = pd.DataFrame({\"cv_loss\": [0 for i in range(0,hyp_pd.shape[0])], \"best_epoch\": [0 for i in range(0,hyp_pd.shape[0])]})\n",
    "   return hyp_pd, hyp_seq_grid, empty_res\n",
    "\n",
    "# internal function for cross-validation: optimal order of running different hyperparameter scenarios: calculates a 'scenario distance' by finding scenarios that are maximally contrasting with each other\n",
    "def optimal_order_of_hyperparameter_runs(hyp_seq_grid):\n",
    "   scenario_dist = -2 * np.dot(hyp_seq_grid, hyp_seq_grid.T) + np.sum(hyp_seq_grid**2, axis=1) + np.sum(hyp_seq_grid**2, axis=1)[:, np.newaxis]\n",
    "   scenario_rows = [0] # start with row 1\n",
    "   for i in range(0,hyp_seq_grid.shape[0]):\n",
    "      cur_dist = -2 * np.dot(hyp_seq_grid, hyp_seq_grid[scenario_rows].T) + np.sum(hyp_seq_grid[scenario_rows]**2, axis=1) + np.sum(hyp_seq_grid**2, axis=1)[:, np.newaxis]\n",
    "      elem_rank_by_distance = rd(-(((cur_dist**2)).sum(axis=1))**(0.5)).argsort()\n",
    "      pos_elem = [x for x in elem_rank_by_distance if x not in scenario_rows]\n",
    "      if len(pos_elem)>0:\n",
    "         scenario_rows.append(pos_elem[0])\n",
    "   return scenario_rows\n",
    "\n",
    "# internal function for cross-validation: make validation sets and test sets\n",
    "def make_cv_weights(n_obs, fHoldoutProportion = 0.5, kfold = 3, seed = 1000):\n",
    "   # trainging set and test set\n",
    "   ix_train, ix_test = train_test_split([i for i in range(0,n_obs)], test_size = fHoldoutProportion, random_state = seed)\n",
    "   # divide the training data into cross-validation sets\n",
    "   cv_splitter = KFold(n_splits = kfold)\n",
    "   cv_sets = []\n",
    "   for ix_insample, ix_validation in cv_splitter.split(ix_train):\n",
    "      cv_sets.append([ix_insample, ix_validation])\n",
    "   return ix_train, ix_test, cv_sets\n",
    "\n",
    "# internal function for cross-validation: propose hyperparameters, by two methods:\n",
    "# ... i) sequential (just loops through combinations)\n",
    "# ... ii) thompson sampling / multi-arm bandit reinforcement learner (ridge regression & decision trees to try to predict what might be best hyperparameters)\n",
    "def proposal_hyperparam(run_number, # iteration number for the algorithm\n",
    "                        cv_results, # current results of the cv-loss (panda frame)\n",
    "                        hyp_pd, # output from \"make_hyperparameters_combos\" function\n",
    "                        hyp_optimal, # output from \"make_hyperparameters_combos\" function\n",
    "                        toggle_learner = 10, # when to switch to mult-arm bandit learning\n",
    "                        ridge_alpha = 7, # ridge regression learner: shrinkage parameter\n",
    "                        max_depth = 2, # tree-learner maximum tree depth\n",
    "                        multinomial_prior = 1): # diffuse prior on the model space for the multi-arm bandit \n",
    "   n_models = len(hyp_optimal)\n",
    "   if (run_number < toggle_learner) | (run_number > (hyp_pd.shape[0]-1)):\n",
    "      # just sequentially loop through hyperparameter combos\n",
    "      print(\"next hyperparameter: estimated by maximum parameter contrast\")\n",
    "      return_hypIx = hyp_optimal[run_number]\n",
    "      return_hyperparameters = hyp_pd.iloc[return_hypIx]\n",
    "   else:\n",
    "      print(\"next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\") \n",
    "        # find which hyperparam/combos are already completed (used for estimation)\n",
    "      which_done = np.where(cv_results['best_epoch'].values >0)\n",
    "      # find which hyperparam/combos are not yet run (used for predicting their loss)\n",
    "      which_notdone = np.where(cv_results['best_epoch'].values == 0)\n",
    "      # train a ridge regression \n",
    "      learner1 = Ridge(alpha=ridge_alpha, copy_X = True,normalize=True)\n",
    "      # train a decision tree\n",
    "      learner2 = DecisionTreeRegressor(max_depth = max_depth)\n",
    "      # multi-arm bandit: use leave-one-out estimation to get frequency counts that each combo is the best\n",
    "      counts_best_loss = np.zeros(len(which_notdone[0])) + multinomial_prior # notice shrinkage parameter multinomial_prior=1\n",
    "      # loop through each completed combo and drop it (leave-one-out subsampling)\n",
    "      for j in range(0,len(which_done[0])):\n",
    "         # drop the j'th combo (leave-one-out)\n",
    "         loo = which_done[0][np.arange(len(which_done[0]))!=j]\n",
    "         # fit learners\n",
    "         lr1 = learner1.fit(X = hyp_pd.values[loo], y = cv_results['cv_loss'].values[loo]) \n",
    "         lr2 = learner2.fit(X = hyp_pd.values[loo], y = cv_results['cv_loss'].values[loo]) \n",
    "         # predict which will be the lowest loss         \n",
    "         pred_loss1 = lr1.predict(hyp_pd.values[which_notdone]) # expected loss from the learner\n",
    "         pred_loss2 = lr2.predict(hyp_pd.values[which_notdone]) # expected loss from the learner         \n",
    "         # increment number of time's each hypparam/combo is predicted to be the best\n",
    "         counts_best_loss += 0.5*(pred_loss1 == min(pred_loss1))\n",
    "         counts_best_loss += 0.5*(pred_loss2 == min(pred_loss2))\n",
    "      # convert selection frequency of each combo into a probability (Dirichlet)\n",
    "      thompson_sampling_prob = np.random.dirichlet(counts_best_loss)\n",
    "      # Thompson sampler: random sample from the probabilities (Multinomial)\n",
    "      return_hypIx = np.random.choice(which_notdone[0],p=thompson_sampling_prob)\n",
    "      # get the index of the hyperparameters for the best expectd loss\n",
    "      # hyperparameters for the best expectd loss\n",
    "      return_hyperparameters = hyp_pd.iloc[return_hypIx]\n",
    "   return return_hypIx, return_hyperparameters \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions: K-fold Cross-Validation\n",
    "The following functions support the 3-fold cross validation. The are fairly self-explanatory. The main functions are:\n",
    "+ `make_cv_weights` : splits the data into two indices for training & testing. Among the training indices (`ix_train`), it further divides the data into mutually exclusive k-fold cross-validation sets (`cv_sets`). You tune the hyperparameters with the subsets in `cv_sets`; you train a final (tuned) model on the `ix_train`, and you validate the final model on the hold-out set `ix_test`.\n",
    "+ `run_model` : runs an LSTM model using the `keras` API; \n",
    "+ `run_cv_model`: calls `run_model` for one CV-iteration; ONLY returns the validation loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal function for cross-validation: make validation sets and test sets\n",
    "def make_cv_weights(n_obs, fHoldoutProportion = 0.5, kfold = 3, seed = 1000):\n",
    "   # trainging set and test set\n",
    "   ix_train, ix_test = train_test_split([i for i in range(0,n_obs)], test_size = fHoldoutProportion, random_state = seed)\n",
    "   # divide the training data into cross-validation sets\n",
    "   cv_splitter = KFold(n_splits = kfold)\n",
    "   cv_sets = []\n",
    "   for ix_insample, ix_validation in cv_splitter.split(ix_train):\n",
    "      cv_sets.append([ix_insample, ix_validation])\n",
    "   return ix_train, ix_test, cv_sets\n",
    "\n",
    "# function: LSTM model, using Keras functional API\n",
    "# use the Keras API to build the model\n",
    "# Main LSTM model. Two inputs: X=word features (tokenized); X_labels=matrix of categories [1,2,3,...,nLabels]\n",
    "# ... the output is Y: one-hot-coding of labels for each row of X,X_labels.\n",
    "# Notice the `RepeatVector` which merges the output from the LSTM with the output from the Category embedding\n",
    "def run_model(X, # tokenized text\n",
    "              X_labels, # categories vector [1,2,3,...]\n",
    "              Y, # labels (one-hot-coding)\n",
    "              W, # sample weights\n",
    "              X_val, # out-of-sample validation: X\n",
    "              X_labels_val, # # out-of-sample validation: X_labels\n",
    "              Y_val, # # out-of-sample validation: Y\n",
    "              max_tokens, # number of words/tokens used to tokenize sentences\n",
    "              n_epoch = 30, # hyperparameter\n",
    "              batch_size = 64, # hyperparameter\n",
    "              dim_embed_lstm= 200, # word embedding dimension\n",
    "              dim_out_lstm =100, # dimension of LSTM output\n",
    "              fDropout_RNN=0.1, # regularization: recurrent_dropout for LSTM\n",
    "              fDropout=0.33, # regularization: input dropout for LSTM\n",
    "              dim_embed_categ=5, # embedding dimension of the categories\n",
    "              dim_hidden_nodes_final =100): # number of hidden nodes in final Dense layer\n",
    "   nLabels = X_labels.shape[1]\n",
    "   # main input: the word features (tokenized) \n",
    "   lstm_input_layer = Input(shape=(X.shape[1],), dtype='int32', name='lstm_input',) # lstm input\n",
    "   # word embedding (like word2vec)\n",
    "   lstm_embed_layer = Embedding(input_dim=max_tokens, output_dim=dim_embed_lstm, input_length=X.shape[1])(lstm_input_layer)\n",
    "   lstm_output = LSTM(dim_out_lstm, dropout = fDropout, recurrent_dropout = fDropout_RNN)(lstm_embed_layer)\n",
    "   # reshape the LSTM output to concatenate with the category embedding\n",
    "   lstm_reshape = RepeatVector(nLabels)(lstm_output)  \n",
    "   label3_input_layer = Input(shape=(X_labels.shape[1],), dtype='int32', name='label3_input') # input the topics\n",
    "   label3_embed_layer = Embedding(input_dim=nLabels, output_dim = dim_embed_categ, input_length=X_labels.shape[1])(label3_input_layer) # topic embedding: should have dim: None,7,embed_dim\n",
    "   # merge the LSTM output with the category embedding\n",
    "   x = concatenate([lstm_reshape,label3_embed_layer],axis=2) # \n",
    "   # final hidden layer\n",
    "   hidden_layer = Dense(dim_hidden_nodes_final, activation='relu')(x)\n",
    "   final_layer = Dense(1, activation='sigmoid')(hidden_layer) # main output for categories\n",
    "   # reshape the output so that it is multinomial in [n_obs, n_categories]\n",
    "   final_layer2 = Flatten()(final_layer) # dimension: [n_obs, n_categories]\n",
    "   main_output = Dense(Y.shape[1], activation='softmax',name = 'main_output')(final_layer2) # main output for categories \n",
    "   model = Model(inputs=[lstm_input_layer, label3_input_layer], outputs=[main_output])\n",
    "   model.compile(loss = \"categorical_crossentropy\", optimizer='adam') \n",
    "   history = model.fit({'lstm_input': X, 'label3_input': X_labels }, {'main_output': Y}, epochs = n_epoch, batch_size=batch_size, verbose = 0, sample_weight = W, validation_data=([X_val, X_labels_val], Y_val))\n",
    "   return model, history\n",
    "\n",
    "# main function: run individual cv-run; ONLY returns the validation loss (deletes model)\n",
    "def run_cv_model(cv_insample_indices,cv_validation_indices, Y, cText, X_labels, vWeights, hyperparam, n_epoch = 7, fDropout_RNN = 0.1, batch_size = 64):\n",
    "   n_obs = Y.shape[0] # number of observations/rows\n",
    "   # get hyperparameters\n",
    "   iMaxTokens = int(hyperparam['max_tokens']) # maximum number of words in corpus for embedding\n",
    "   iDimEmbedLSTM = int(hyperparam['DimEmbedLSTM']) # embedding dimensions for words\n",
    "   iDimOutLSTM = int(hyperparam['DimOutLSTM']) # LSTM output dimension\n",
    "   fDropout = hyperparam['Dropout'] # LSTM input dropout regularization\n",
    "   iDimEmbedCategory = int(hyperparam['DimEmbedCategory'])\n",
    "   iDim_hidden_nodes_final = (np.linspace(iDimOutLSTM,Y.shape[1]).round().astype(int))[1] # number of    \n",
    "   # tokenize the text\n",
    "   tokenizer = Tokenizer(num_words=iMaxTokens, split=' ')\n",
    "   tokenizer.fit_on_texts(\"STARTCODON \" + cText[0])\n",
    "   # text data: insample and validation\n",
    "   X = pad_sequences(tokenizer.texts_to_sequences((\"STARTCODON \" + cText[0]).values)) # tokenize and pad with zeros\n",
    "   X_insample = X[cv_insample_indices] \n",
    "   X_val = X[cv_validation_indices]\n",
    "   # label data (N-hot-coding): insample and validation\n",
    "   Y_insample = Y[cv_insample_indices]\n",
    "   Y_val = Y[cv_validation_indices]\n",
    "   # labels for category embedding\n",
    "   X_labels_insample = X_labels[cv_insample_indices]\n",
    "   X_labels_val = X_labels[cv_validation_indices]\n",
    "   # training weights\n",
    "   W_insample = vWeights[cv_insample_indices]\n",
    "   # fit the model\n",
    "   model, history = run_model(X_insample, X_labels_insample, Y_insample, W_insample, \n",
    "                              X_val,X_labels_val,Y_val, \n",
    "                              iMaxTokens, \n",
    "                              n_epoch, \n",
    "                              batch_size, \n",
    "                              iDimEmbedLSTM, \n",
    "                              iDimOutLSTM, \n",
    "                              fDropout_RNN, \n",
    "                              fDropout, \n",
    "                              iDimEmbedCategory, \n",
    "                              iDim_hidden_nodes_final)\n",
    "   val_loss = history.history['val_loss']\n",
    "   del model\n",
    "   del history\n",
    "   return val_loss\n",
    "\n",
    "# internal function for cross-validation: get the best epoch over k-fold validation\n",
    "def get_best_epoch(cv_losses):\n",
    "      expected_loss_per_epoch = (np.array(cv_losses).T).mean(axis=1)\n",
    "      best_epoch = expected_loss_per_epoch.argmin() + 1\n",
    "      return best_epoch, expected_loss_per_epoch[best_epoch-1]\n",
    "\n",
    "# internal function for cross-validation: get best hyperparameter combinations from CV-loss results\n",
    "def get_best_hyperparameters(cv_results, hyperparameter_grid):\n",
    "   which_done = np.where(cv_results['best_epoch'].values!=0)\n",
    "   which_best = which_done[0][cv_results['cv_loss'].values[which_done[0]].argmin()]\n",
    "   best_epoch = cv_results['best_epoch'][which_best]\n",
    "   return hyperparameter_grid.iloc[which_best], best_epoch \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: import and process data\n",
    "\n",
    "+ NLP the text data (`cText`). \n",
    "+ Convert the categories/labels into one-hot-coding (`Y`)\n",
    "+ Make the category embedding (`X_labels3`).\n",
    "+ Make sample weights (`vWeights`) for the keras `sample_weight` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decompressing complaints-2018-09-30_17_53.csv.tar.xz into /tmp/\n",
      "tar xf data/complaints-2018-09-30_17_53.csv.tar.xz -C /tmp/\n",
      "imported 191828 rows of data\n",
      "performing NLP pre-processing on column Consumer complaint narrative (remove stop words, stemming,...). This may take a while...\n",
      "Done NLP pre-processing\n",
      "returning cleaned text data 'cText' for use in tokenization; 'Y' as an one-hot-coding matrix of categories; and 'cats' a dictionary matches columns in Y to english category names\n",
      "deleting temporary file complaints-2018-09-30_17_53.csv.tar.xz\n",
      "rm /tmp/complaints-2018-09-30_17_53.csv\n",
      "done pre-processing\n",
      "number of observations:191193\n",
      "number of categories:425\n"
     ]
    }
   ],
   "source": [
    "# import and clean the data.\n",
    "# Returns 'cText' (the NLP-preprocessed data) and 'cats' (the dictionary of categories/labels for classification')\n",
    "cText, Y, X_labels3, cats = import_and_clean_data(filename = \"complaints-2018-09-30_17_53.csv.tar.xz\", # filename to import the data,\n",
    "    #filename = \"complaints-2018-09-30_17_53.csv\", # filename to import the data,     \n",
    "                                    col_label = \"Label3\", # label to work with for classification/learning\n",
    "                                    data_dir = \"data/\", # directory\n",
    "                                    tmp_dir = \"/tmp/\", # if file is a .tar.xz, where to temporarily extract the data (Windows users need specify differently than /tmp/\n",
    "                                    rare_categories_cutoff = 10, # threshold for categories to be included in the training set\n",
    "                                    word_clip = 300) # max number of words in text to accept (only first 300 words are retained\n",
    "\n",
    "n_obs = Y.shape[0]\n",
    "nLabels3 = X_labels3.shape[1]\n",
    "print(\"number of observations:\" + str(n_obs))\n",
    "print(\"number of categories:\" + str(nLabels3))\n",
    "      \n",
    "# sample weights to correct for unbalanced categories / labels\n",
    "vWeights = get_class_weights(Y,5) # weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: define the hyperparameters and set-up cross-validation\n",
    "### validation sets\n",
    "+ `kfold` : used for k-fold cross-validation; I use 3-fold validation\n",
    "+ `fHoldoutProportion` : used to define the proportion of data not-used for training, but for validating the final model.\n",
    "\n",
    "### hyperparameter space\n",
    "+ `max_tokens`: the size of the corpus used in the word-tokenization (which feeds into the word-embedding).\n",
    "+ `DimEmbedLSTM`:the embedding dimension of the word-embedding (like word2vec) \n",
    "+ `DimOutLSTM` : the dimensionality of the Long-Short-Term-memory outputs\n",
    "+ `Dropout` regularization parameter: dropout rate in the LSTM\n",
    "+ `DimEmbedCategory`: the embedding dimension of the category-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training set: 22943; size of test set 168250\n"
     ]
    }
   ],
   "source": [
    "kfold = 3 # k-fold cross-validation\n",
<<<<<<< HEAD
    "fHoldoutProportion = 0.6 # amount of data to leave aside for (final) hold-out validation\n",
=======
    "fHoldoutProportion = 0.88 # amount of data to leave aside for (final) hold-out validation\n",
>>>>>>> 8c849955f0eab83bf762c3c597bd6ec0aabeb1d3
    "\n",
    "# hyperparmeters' and their values\n",
    "hyper_parameters = {'max_tokens': [1500,2000,3000], # number of wor tokens\n",
    "                    'DimEmbedLSTM':[60,90,120,180], # word embedding dimension\n",
    "                    'DimOutLSTM':[60,90,120,150], # LSTM output dimension\n",
    "                    'Dropout':[0.20,0.33,0.5], # dropout proportion for LSTM\n",
    "                    'DimEmbedCategory':[3,5,8,11]} # category embedding\n",
    "\n",
    "# hyperparameters: make all possible combinations of \n",
    "hyp_grid, ix_hyp_grid, cv_results = make_hyperparameters_combos(hyper_parameters)\n",
    "optimal_hyp_order = optimal_order_of_hyperparameter_runs(ix_hyp_grid)\n",
    "\n",
    "# training set, testing sets, and cross-validation sets: indicies to divide the data\n",
    "ix_train,ix_test,cv_sets = make_cv_weights(n_obs, fHoldoutProportion = fHoldoutProportion, kfold = kfold, seed = 1000)\n",
    "print(\"size of training set: %s; size of test set %s\" % (str(len(ix_train)), str(len(ix_test))))\n",
    "\n",
    "\n",
    "n_epoch = 17 # number of epochs\n",
    "batch_size = 200 # batchsize\n",
    "pause_seconds = 120 # pause between CV-iterations\n",
    "fDropout_RNN = 0.1 # recurrent_dropout for LSTM (not tunned)\n",
    "\n",
    "# big loop to run through hyperparameters\n",
    "max_hyperparameter_runs = min(25, len(optimal_hyp_order)) # maximum number of iterations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Explore the hyperparameter space (cross-validation)\n",
    "This is the main part of the exercise, consisting of two massive loops. The outer loop iterates through different hyperparameter values, and the inner loop iterates through the K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-fold hyperparameter estimation algorithm for 25iterations\n",
      "hyperparameter tuning, iteration: 0\n",
      "next hyperparameter: estimated by maximum parameter contrast\n",
      "[1.5e+03 6.0e+01 6.0e+01 2.0e-01 3.0e+00]\n",
      "done iteration 0. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 1\n",
      "next hyperparameter: estimated by maximum parameter contrast\n",
      "[3.0e+03 1.8e+02 1.5e+02 5.0e-01 1.1e+01]\n",
      "done iteration 1. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 2\n",
      "next hyperparameter: estimated by maximum parameter contrast\n",
      "[1.5e+03 6.0e+01 6.0e+01 3.3e-01 3.0e+00]\n",
      "done iteration 2. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 3\n",
      "next hyperparameter: estimated by maximum parameter contrast\n",
      "[3.0e+03 1.8e+02 1.5e+02 2.0e-01 1.1e+01]\n",
      "done iteration 3. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 4\n",
      "next hyperparameter: estimated by maximum parameter contrast\n",
      "[1.5e+03 6.0e+01 6.0e+01 5.0e-01 3.0e+00]\n",
      "done iteration 4. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 5\n",
      "next hyperparameter: estimated by maximum parameter contrast\n",
      "[3.0e+03 1.8e+02 1.5e+02 3.3e-01 1.1e+01]\n",
      "done iteration 5. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 6\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[1.5e+03 9.0e+01 6.0e+01 5.0e-01 5.0e+00]\n",
      "done iteration 6. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 7\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[2.0e+03 1.8e+02 1.5e+02 2.0e-01 5.0e+00]\n",
      "done iteration 7. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 8\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[2.0e+03 1.8e+02 9.0e+01 5.0e-01 3.0e+00]\n",
      "done iteration 8. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 9\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[3.0e+03 6.0e+01 1.2e+02 3.3e-01 3.0e+00]\n",
      "done iteration 9. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 10\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[2.0e+03 1.8e+02 1.5e+02 3.3e-01 1.1e+01]\n",
      "done iteration 10. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 11\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[2.0e+03 9.0e+01 9.0e+01 3.3e-01 8.0e+00]\n",
      "done iteration 11. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 12\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[1.5e+03 1.2e+02 9.0e+01 2.0e-01 3.0e+00]\n",
      "done iteration 12. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 13\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[3.0e+03 1.2e+02 1.2e+02 3.3e-01 8.0e+00]\n",
      "done iteration 13. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 14\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[2.0e+03 1.2e+02 9.0e+01 2.0e-01 5.0e+00]\n",
      "done iteration 14. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 15\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[3.0e+03 1.2e+02 9.0e+01 3.3e-01 5.0e+00]\n",
      "done iteration 15. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 16\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[3.0e+03 1.8e+02 6.0e+01 3.3e-01 5.0e+00]\n",
      "done iteration 16. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 17\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[3.0e+03 1.2e+02 9.0e+01 2.0e-01 5.0e+00]\n",
      "done iteration 17. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 18\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[3.0e+03 1.2e+02 9.0e+01 3.3e-01 3.0e+00]\n",
      "done iteration 18. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 19\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[3.0e+03 9.0e+01 6.0e+01 2.0e-01 1.1e+01]\n",
      "done iteration 19. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 20\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[1.5e+03 9.0e+01 9.0e+01 3.3e-01 3.0e+00]\n",
      "done iteration 20. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 21\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[3.0e+03 1.2e+02 9.0e+01 5.0e-01 5.0e+00]\n",
      "done iteration 21. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 22\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[1.5e+03 9.0e+01 6.0e+01 3.3e-01 8.0e+00]\n",
      "done iteration 22. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 23\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[1.5e+03 6.0e+01 9.0e+01 2.0e-01 5.0e+00]\n",
      "done iteration 23. Sleeping for 120 seconds.\n",
      "hyperparameter tuning, iteration: 24\n",
      "next hyperparameter: Thompson sampling of hyperparameters based on a multi-arm bandit learner\n",
      "[1.5e+03 6.0e+01 9.0e+01 2.0e-01 1.1e+01]\n",
      "done iteration 24. Sleeping for 120 seconds.\n",
      "done k-fold hyperparameter estimation: hit 25 iterations\n"
     ]
    }
   ],
   "source": [
    "i = 0 # iterator, outer loop\n",
    "print(\"running k-fold hyperparameter estimation algorithm for \" + str(max_hyperparameter_runs) + \"iterations\")\n",
    "while i < max_hyperparameter_runs:\n",
    "   print(\"hyperparameter tuning, iteration: \" + str(i))\n",
    "   # proposal new hyperparameters from the space of combinations\n",
    "   ixHyper, current_hyper_param = proposal_hyperparam(i, cv_results, hyp_pd = hyp_grid, hyp_optimal = optimal_hyp_order, toggle_learner = 6, ridge_alpha = 7)\n",
    "   print(current_hyper_param.values)\n",
    "   # do cross-validation\n",
    "   k_loss = [] # validation loss results\n",
    "   # inner loop, cross-validation\n",
    "   for icv, lcv_set in enumerate(cv_sets):\n",
    "      k_loss.append(run_cv_model(lcv_set[0],lcv_set[1], Y, cText, X_labels3, vWeights, current_hyper_param, n_epoch = n_epoch, fDropout_RNN = 0.1, batch_size = batch_size))\n",
    "   # return best mean(validation_loss) at which epoch \n",
    "   best_epoch, k_expected_loss = get_best_epoch(k_loss) # get best epoch and expected loss\n",
    "   cv_results['best_epoch'].iloc[ixHyper] = best_epoch\n",
    "   cv_results['cv_loss'].iloc[ixHyper] = k_expected_loss\n",
    "   print(\"done iteration \"+ str(i)+ \". Sleeping for \" + str(pause_seconds) +\" seconds.\")\n",
    "   time.sleep(pause_seconds)\n",
    "   # repeat\n",
    "   i += 1\n",
    "\n",
    "print(\"done k-fold hyperparameter estimation: hit \" + str(max_hyperparameter_runs) + \" iterations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Set Hyperparameters based on CV results\n",
    "Let's inspect the results of the hyperparameter tuning. Ideally, we would run this 1000 times, but due to time constrants, we will have to unfortunately stop short at 25 runs (better than nothing). We will also plot the relationship between the CV-loss and the hyperparameters, to get a sense of the relationships.\n",
    "\n",
    "The results suggest that a LOW embedding dimension for categories is best (3) and a fairly aggressive dropout rate. The tune seems most adamant about the need for a LOW LSTM output dim (iDimOutLSTM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     max_tokens  DimEmbedLSTM  DimOutLSTM  Dropout  DimEmbedCategory  \\\n",
      "500      2000.0         180.0        90.0     0.50               3.0   \n",
      "300      1500.0         120.0        90.0     0.20               3.0   \n",
      "349      2000.0         120.0        90.0     0.20               5.0   \n",
      "401      3000.0         120.0        90.0     0.33               5.0   \n",
      "160      1500.0          90.0        90.0     0.33               3.0   \n",
      "8        1500.0          60.0        60.0     0.50               3.0   \n",
      "0        1500.0          60.0        60.0     0.20               3.0   \n",
      "150      1500.0          90.0        60.0     0.33               8.0   \n",
      "243      3000.0          90.0        60.0     0.20              11.0   \n",
      "13       1500.0          60.0        90.0     0.20               5.0   \n",
      "517      2000.0         180.0       150.0     0.20               5.0   \n",
      "4        1500.0          60.0        60.0     0.33               3.0   \n",
      "397      3000.0         120.0        90.0     0.20               5.0   \n",
      "575      3000.0         180.0       150.0     0.50              11.0   \n",
      "571      3000.0         180.0       150.0     0.33              11.0   \n",
      "15       1500.0          60.0        90.0     0.20              11.0   \n",
      "210      2000.0          90.0        90.0     0.33               8.0   \n",
      "153      1500.0          90.0        60.0     0.50               5.0   \n",
      "414      3000.0         120.0       120.0     0.33               8.0   \n",
      "533      3000.0         180.0        60.0     0.33               5.0   \n",
      "\n",
      "      cv_loss  best_epoch  \n",
      "500  5.471098          16  \n",
      "300  5.499793          15  \n",
      "349  5.500208           3  \n",
      "401  5.540469          10  \n",
      "160  5.556176          14  \n",
      "8    5.556656          15  \n",
      "0    5.565775           6  \n",
      "150  5.569431          17  \n",
      "243  5.575677          10  \n",
      "13   5.578560           6  \n",
      "517  5.579830          15  \n",
      "4    5.582285          14  \n",
      "397  5.582795           3  \n",
      "575  5.583952           5  \n",
      "571  5.588760          10  \n",
      "15   5.598004           7  \n",
      "210  5.598124          13  \n",
      "153  5.601875           4  \n",
      "414  5.606966           8  \n",
      "533  5.607379           7  \n"
     ]
    }
   ],
   "source": [
    "# process the CV results: get best hyperparameters\n",
    "best_hyperparameters, n_epoch = get_best_hyperparameters(cv_results, hyp_grid)\n",
    "cv_results_sort = pd.concat([pd.DataFrame(hyp_grid),cv_results],axis=1)\n",
    "cv_results_sort = cv_results_sort[cv_results_sort['best_epoch']!=0]\n",
    "\n",
    "# Final best hyperparameters\n",
    "iMaxTokens = int(best_hyperparameters['max_tokens'])\n",
    "iDimEmbedLSTM = int(best_hyperparameters['DimEmbedLSTM'])\n",
    "iDimOutLSTM = int(best_hyperparameters['DimOutLSTM'])\n",
    "fDropout = best_hyperparameters['Dropout']\n",
    "iDimEmbedCategory = int(best_hyperparameters['DimEmbedCategory'])\n",
    "iDim_hidden_nodes_final = (np.linspace(iDimOutLSTM,Y.shape[1]).round().astype(int))[1] \n",
    "\n",
    "print(\"best number of word tokens is %s (iMaxTokens); best word-embedding dimension for the LSTM is %s (iDimEmbedLSTM); best out-dimension for the LSTM is %s (iDimOutLSTM); best dropout rate for LSTM is %s (fDropout); best embedding dimension size for category-embedding is %s (iDimEmbedCategory)\" % [str(iMaxTokens),str(iDimEmbedLSTM),str(iDimOutLSTM),str(round(fDropout,2)),str(iDimEmbedCategory])\n",
    "\n",
    "# inspect the top 20 models, sorted by cross-validation loss\n",
    "print(cv_results_sort.sort_values(by=['cv_loss']).iloc[0:20,:])\n",
    "\n",
    "# plot the relationship between hyperparameters an loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Run the final 'tuned' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit final model\n",
    "ix_train,ix_test,cv_sets = make_cv_weights(n_obs, fHoldoutProportion = 0.5, kfold = kfold, seed = 1000)\n",
    "tokenizer = Tokenizer(num_words=iMaxTokens, split=' ')\n",
    "tokenizer.fit_on_texts(\"STARTCODON \" + cText[0])\n",
    "# text data: insample and validation\n",
    "X = pad_sequences(tokenizer.texts_to_sequences((\"STARTCODON \" + cText[0]).values)) # tokenize and pad with zeros\n",
    "\n",
    "# subset the input/response data by training and test sets\n",
    "X_train = X[ix_train]; \n",
    "X_labels3_train = X_labels3[ix_train]; \n",
    "Y_train = Y[ix_train];\n",
    "W_train = vWeights[ix_train]\n",
    "# testing: for final validation\n",
    "X_test = X[ix_test]\n",
    "X_labels3_test = X_labels3[ix_test]\n",
    "Y_test = Y[ix_test]\n",
    "\n",
    "\n",
    "# final model\n",
    "model, history = run_model(X_train, X_labels3_train, Y_train, W_train, \n",
    "                              X_test,X_labels3_test,Y_test, \n",
    "                              iMaxTokens, \n",
    "                              n_epoch, \n",
    "                              batch_size, \n",
    "                              iDimEmbedLSTM, \n",
    "                              iDimOutLSTM, \n",
    "                              fDropout_RNN, \n",
    "                              fDropout, \n",
    "                              iDimEmbedCategory, \n",
    "                              iDim_hidden_nodes_final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Test the final model\n",
    "Using the holdout data (indices `ix_test`), we will estimate hold-out statistics, like the ROC/AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training set: 95596; size of test set 95597\n"
     ]
    }
   ],
   "source": [
    "# predict the lables on test set\n",
    "print(\"size of training set: %s; size of test set %s\" % (str(len(ix_train)), str(len(ix_test))))\n",
    "pwide =  model.predict([X_test,X_labels3_test]) # predicted probability matrix\n",
    "pvec = pwide.flatten() # vectorize the prediction matrix \n",
    "yvec = Y_test.flatten() # vectorize the one-hot-coding labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global AUC score=0.939111\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC (holdout) score is 0.900972\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the fpr, tpr, and AUC scores\n",
    "global_fpr, global_tpr, threshold = roc_curve(yvec, pvec)\n",
    "global_roc_auc = auc(global_fpr, global_tpr) # \n",
    "print(\"Global AUC score=%f\" % (global_roc_auc))\n",
    "\n",
    "# plot the ROCurve\n",
    "# %matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic (out-of-sample)')\n",
    "plt.plot(global_fpr, global_tpr, 'purple', label = 'Global CV-AUC = %0.2f' % global_roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "#plt.savefig('img/global_roc_default_model.png')\n",
    "plt.show() # to plot in your own terminal\n",
    "#Global AUC score=0.949081\n",
    "\n",
    "# calculate AUC scores per category\n",
    "roc_topic = [] # container for per-category AUC scores\n",
    "Y_labels_test = Y_test.argmax(axis=1)\n",
    "for i in range(0,Y.shape[1]):\n",
    "    tmptopic_fpr, tmptopic_tpr, threshold = roc_curve(Y_test[:,i].flatten(), pwide[:,i].flatten())\n",
    "    roc_topic.append(auc(tmptopic_fpr, tmptopic_tpr))\n",
    "\n",
    "# average ROC/AUC score overall categories\n",
    "print(\"Average AUC (holdout) score is %f\" % (sum(roc_topic)/len(roc_topic)))\n",
    "\n",
    "n, bins, patches = plt.hist(roc_topic, 20, facecolor='blue', alpha=0.5)\n",
    "plt.xlabel('AUC scores (per category)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(r'cv-AUC scores per category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
